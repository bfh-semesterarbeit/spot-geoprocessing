\section{Architektur}

\subsection{Analyse des Ist-Zustandes}
\subsubsection{Bereitstellung der Rohdaten und Sicherstellung dessen Qualität}\label{kap:sicherstellung_qualitaet}
Basierend auf der Aufwandeinschätzung des Ist-Zustandes des Kapitels \ref{aufwand_prozessierung} geht hervor, dass vor allem das Bereitstellen der Rohdaten und das Sicherstellen dessen Qualität aufwändig ist. 

\paragraph{Das Bereitstellen der Rohdaten} nimmt aufgrund der Datenmenge\footnote{Weil es sich um mehrere Millionen Dateien handelt.} viel Zeit in Anspruch. Hier gäbe es folgende zwei Lösungsansätze:
\begin{enumerate}
\item Der Datenlieferant könnte direkt aufs EFS schreiben (Abb. \ref{fig:ist_zustand}, Nr. 5).
\item Automatischer Prozess via Cronjob oder Trigger, der die Kopierschritte (Abb. \ref{fig:ist_zustand}, Schritt 3) regelmässig bereitstellt.
\end{enumerate}

Wobei der Lösungsansatz 1. simpler und weniger fehleranfällig zu sein scheint. Dieser Ansatz könnte, sobald die swisstopo eine Hybrid Cloud hat, weiterverfolgt werden.

\paragraph{Sicherung der Qualität:} Weil es dem Lieferanten an Tools fehlt, um die bereitgestellten Daten inhaltlich zu Prüfen, werden Fehler 
häufig erst nach der Publikation entdeckt. Dies sicherlich auch, weil die Daten im Web an ein breites Publikum gelangen. Da keine inhaltliche Prüfung der Rohdaten gemacht werden kann, wäre es sicher hilfreich, wenn der Datenlieferant die Iterationen der Publizierung gleich selber machen könnte und dann nur noch Bescheid gibt, wenn sie seines Erachtens in Ordnung sind.

\subsubsection{Bereitstellung der Infrastruktur für die Verarbeitung}
Die Rohdaten werden via Docker Image verarbeitet. Jedes Mal wenn das Image für die Verarbeitung ausgeführt werden soll, muss die IT gebeten werden, die nötige Infrastruktur bereitzustellen. Idealerweise findet sich eine Lösung, die diesen Schritt überflüssig macht.


\subsection{Bewertungskriterien}
\begin{tabular}{p{0.3\textwidth}p{0.7\textwidth}}
    \textbf{Kosten einsparen} & Änderungen des Prozesses sollen nicht teurer sein, als die bisherige Lösung.\\
    \textbf{Automatisierbar} & Die Lösung soll den Grad der Automatisierung möglichst weit vorantreiben und dadurch so wenig Personalaufwand wie möglich beanspruchen.\\
    \textbf{Einfach} & Ein neuer Mitarbeiter soll die Lösung rasch verstehen und warten können.\\
    \textbf{Bestehende Technologie} & Obwohl der Anwendungsfall anders ist, soll der Technologie Stack möglichst demjenigen der Web Services entsprechen.\\
\end{tabular}

\subsection{Architekturentscheid}
Für den Architekturentscheid wurde auf eine Entscheidungsmatrix verzichtet. Dies Aufgrund der grossen Auswahl und der vielen Entscheidungen, die getroffen werden mussten. Die oben erwähnten Kriterien wurden in der Entscheidungsfindung mit einbezogen und weitere Argumente werden ausgeführt:

\subsubsection{Verarbeitung auf Spot Instanzen}
Der Autor ist auf drei Möglichkeiten gestossen, um Geodaten mit AWS Spot Instanzen zu verarbeiten: \emph{Direkt auf der Spot Instanz}, \emph{Kubernetes (EKS)} und \emph{AWS Batch}. Gerne hätte der Autor alle drei Lösungen als Prototyp weiterverfolgt, aber die Zeit dazu reichte leider nicht. Aus diesem Grund beschränkt sich der Autor lediglich auf eine Beschreibung der drei Möglichkeiten. Wobei die erste Möglichkeit als Prototyp umgesetzt wurde.\\
Dies vor allem, weil es der einfachste Ansatz ist, mit der Idee vom Einfachen zum Komplexeren zu schreiten.
Bezüglich Automatisierung konnte auf der Basis des Ist-Zustandes, aufgezeigt werden, dass viele Verarbeitungsschritte nicht direkt mit dem Ausführen des AGI-Containers (Abb. \ref{fig:ist_zustand}, Schritt 6) zu tun haben. Möchte man die anderen Werkzeuge, die für die Datenverarbeitung verwendet werden, auch in Container packen, müsste entweder ein weiterer Container provisioniert - oder der schlanke\footnote{Die Grösse des Containers ist klein gehalten und nur mit dem Nötigsten, das für die Erstellung von Cesium3DTiles verwendet wird, ausgestattet.} AGI-Container erweitert werden.

\paragraph{Direkt auf einer Spot Instanz:}
Diese Möglichkeit bedingt nur geringe Anpassungen der bisherigen Verarbeitung, weil die Daten im Prinzip wie bisher auf einer EC2 Instanz verarbeitet werden; jedoch mit der Herausforderung, dass diese jederzeit durch eine andere Instanz ersetzt werden könnte.

Der Autor hat sich bei der Auswahl der Images\footnote{AMI: Amazon Machine Image.} für \emph{Ubuntu Server 18.04 LTS} entschieden. Dies weil die Verarbeitung bisher auf Ubuntu gelaufen ist und weil er keinen Grund sieht, etwas Funktionierendes zu ändern\footnote{Security Maintenance bis 2028 \cite{Ubuntu2020}.}. Dasselbe Argument gilt für die Wahl der Dimensionierung des Servers: Ein Server mit 200 GB SSD Festplatte, 16 CPUs und 60 GByte Arbeitspeicher konnte die Verarbeitung der 3D Daten\footnote{Gebäude, Bäume und Namen.} gut stemmen.

Bei der Provisionierung\footnote{Bereitstellung} des Servers wurde der \emph{"Cloud-init"} Ansatz\footnote{Eigentlich ein Bash Skript. Unter AWS als \emph{User Data} bezeichnet.} gewählt: Dieser Ansatz provisioniert die Instanz während der Startup Phase. Dies hat gegenüber einem eigenen AMI den Vorteil, dass die Anforderungen in einer Textdatei festgehalten und somit jederzeit nachvollziehbar sind. Ausserdem muss bei einem Update des Basis Images kein neues Image gebaut werden.
Die Initialisierungsskript wurde auf ein Minimum beschränkt und die eigentliche Initialisierung wird an \emph{Ansible} übergeben. 

\paragraph{AWS Batch auf Spot Instanzen}
AWS Batch ist ein interessanter Ansatz zur Geodatenverarbeitung. Der Dienst wurde für genau diese Art von Aufgaben gebaut. Verarbeitungen, oder Teile davon, können auch auf Spot Instanzen erledigt werden. Es kann sogar definiert werden, ab welchem Preis der Batch Job gestartet werden soll. Für den Use Case geht der Autor davon aus, dass folgende Elemente in AWS Batch definiert werden müssten \cite{Batch2020}: 
\begin{itemize}
\item{\textbf{Compute Environment(s):} Die Anforderungen an den Rechner.}
\item{\textbf{Job Queue(s):}: Da sich der Datenumbau nicht ohne weiteres Parallelisieren lässt, wäre dies lediglich die Verbindung zum Compute Environment.}
\item{\textbf{Job Definition(s):}} Der parametrisierte Aufruf des AGI-Containers.
\end{itemize}
Da die Semesterarbeit sich vor allem mit Spot Instanzen generell befasst, die Zeit beschränkt ist und die Einstiegshürde in AWS Batch dem Autor relativ komplex erscheint, wurde von dieser Möglichkeit abgesehen. Falls die Zeit einmal reichen sollte, würde der Autor gerne folgende Demo an die Geodatenverarbeitung anpassen:
\href{https://aws.amazon.com/de/blogs/compute/creating-a-simple-fetch-and-run-aws-batch-job/}{https://aws.amazon.com/de/blogs/}.

\paragraph{Kubernetes (EKS) auf Spot Instanzen erweitern}
Wie in der Ausgangslage (Kap. \ref{kap:webservices}) beschrieben, geben die Web Services den Technologie Stack vor. Idealerweise läuft die Geodatenpublikation auf demselben Stack; inklusive Logging, Monitoring etc.. 
Die Web Services der Geodateninfrastruktur des Bundes werden in Zukunft auf EKS laufen. In diesem Kapitel wird theoretisch untersucht, inwiefern sich die \textit{Geodatenverareitung mittels Spot Instanzen auf Amazon EKS} umsetzen lässt\footnote{In diesem Kapitel ist das Jargon leider etwas Kubernetes-lastig.}. 

Generell ist der Einsatz von Spot Instanzen in einer Kubernetes Umgebung interessant, vor allem bei Web Services. Spot Instanzen sind eine kostensparende Wahl für den Kubernetes Cluster. Nicht für den kompletten Cluster, weil Kubernetes im Grundsatz dazu verwendet wird, um eine hohe Erreichbarkeit zu garantieren. Mehr, um den Cluster mit günstigen Ressourcen zu versorgen, wenn vorausgesehen werden kann, dass höhere Anforderungen an die Rechenkapazität anstehen \autocite[89]{CloudNativ:1}. Im Falle der Web Services des Bundeportales: Wenn man weiss, dass ein schönes Wanderwochenende bevorsteht.\\Aber eben auch, wenn man weiss, dass eine Datenverarbeitung ansteht.
Mit \emph{Node Affinities} kann in Kubernetes gesteuert werden, welche \emph{Pods} auf welchen \emph{Nodes} laufen dürfen \autocite[159]{CloudNativ:1}. Dies ist sehr praktisch, wenn ein bestimmter \emph{Node} auf einer Spot Instanz laufen würde.

Grundsätzlich ist es nicht angedacht, dass man für eine rechenintensive Verarbeitung rasch einen \emph{Pod} auf dem Cluster startet. Dennoch gibt es dafür ein Bordmittel, den \emph{Job}. Der einfachste Use Case ist ein\emph{Job}, der einen einzigen \emph{Pod} startet, um eine Aufgabe, wie bsp. eine Geodatenverarbeitung, zu erledigen. Mittels \emph{Kubernetes CronJob} kann ein Job Sheduling eingerichtet werden, das die \emph{Jobs} zeitlich steuert \cite{9781788390071}.
